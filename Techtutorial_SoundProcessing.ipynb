{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Startup**\n",
    "Load Python libraries for scientific computing and librosa MIR library\n",
    "Set standard parameters for further audio processing\n",
    "Set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Nov 18 14:32:47 2017\n",
    "\n",
    "@author: alexmacbook\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt, IPython.display as ipd\n",
    "import librosa, librosa.display\n",
    "import random\n",
    "import os\n",
    "\n",
    "CHANNELS = 1\n",
    "BYTES_PER_SAMPLE = 2\n",
    "SR = 44100\n",
    "PAD_DURATION = 0.500\n",
    "FRAME_SIZE = 0.14\n",
    "\n",
    "##SOUND STANDARDIZATIO\n",
    "STD_PITCH = 55 #G3\n",
    "BPM = 100.0 #100bpm\n",
    "\n",
    "##FOLDERS\n",
    "PRE_AUDIO = \"pre_audio\"\n",
    "POST_SOUNDS = \"new_post_sounds\"\n",
    "POST_PERCUSSION = \"new_post_percussion\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concatenation of signature sound**\n",
    "Concatenate all onsets at the beginning while onsets have to sum to at least 0.68ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concatenate_segments(x, onset_samples):\n",
    "    #silence = np.zeros(int(pad_duration*SR)) # silence\n",
    "    #frame_sz = min(np.diff(onset_samples))   # every segment has uniform frame size\n",
    "    i = 0\n",
    "    len_onsets = len(onset_samples)\n",
    "    tone = []\n",
    "    while(((onset_samples[i+1])<30000) or (i < 1)): #20000\n",
    "        z = x[onset_samples[i]:onset_samples[i+1]]\n",
    "        tone = np.concatenate([tone, z])\n",
    "        i = i+1\n",
    "    return tone\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concatenation of snare sound**\n",
    "Concatenate all given onsets with silence of 0.5ms at the end\n",
    "Signal length is set to length of shortest onset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concatenate_segments_snare(x, onset_samples, pad_duration=0.500):\n",
    "    \"\"\"Concatenate segments into one signal.\"\"\"\n",
    "    silence = numpy.zeros(int(pad_duration*SR)) # silence\n",
    "    frame_sz = min(np.diff(onset_samples))   # every segment has uniform frame size\n",
    "    return np.concatenate([\n",
    "        np.concatenate([x[i:i+frame_sz], silence]) # pad segment with silence\n",
    "        for i in onset_samples\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adjust speed of audio**\n",
    "Adjust speed to match 100bpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def speed_adjust(x_pre, sr):\n",
    "    onset_env = librosa.onset.onset_strength(x_pre, sr=sr)\n",
    "    tempo = librosa.beat.tempo(onset_envelope=onset_env, sr=sr)\n",
    "    x_fast = librosa.effects.time_stretch(x_pre, BPM/tempo) #TODO\n",
    "    return x_fast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract signature sound**\n",
    "Extract onsets and save the concatenated signal\n",
    "Filter out unusable short samples (hack)\n",
    "Save sample to .wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_sound(path, song_name):\n",
    "    print(path)\n",
    "    x_pre, sr = librosa.load(path, sr=SR)\n",
    "    x_pre = x_pre[0:1000000]\n",
    "    x_fast = speed_adjust(x_pre, sr)\n",
    "    \n",
    "    x = x_fast[0:200000]\n",
    "    onset_frames = librosa.onset.onset_detect(x, sr=sr,  backtrack=True, hop_length=512)\n",
    "    onset_samples = librosa.frames_to_samples(onset_frames)\n",
    "    #onset_times = librosa.frames_to_time(onset_frames, sr=sr)\n",
    "    #clicks = librosa.clicks(times=onset_times, length=len(x))\n",
    "    concatenated_signal = concatenate_segments(x, onset_samples)\n",
    "    print(len(concatenated_signal))\n",
    "\n",
    "    if (len(concatenated_signal) > 4096): #10000\n",
    "        y = concatenated_signal\n",
    "        #pitches, magnitudes = librosa.piptrack(y, sr=sr)\n",
    "        #pitches = pitches[magnitudes > np.median(magnitudes)]\n",
    "        #pitches = [int(a) for (a) in pitches]\n",
    "        #pitch = int(librosa.hz_to_midi(sp.stats.mode(pitches)[0]))\n",
    "        #pitched_y = librosa.effects.pitch_shift(y, SR, n_steps=STD_PITCH-pitch)\n",
    "        librosa.output.write_wav(POST_SOUNDS+'/'+song_name, y, sr)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract audio features**\n",
    "Return Energy value or 0 in case empty sample is provided\n",
    "(Other Features have proven to work worse for finding the chorus of the song with this dirty hack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(x):\n",
    "    if(len(x) > 0):\n",
    "        energy = sp.linalg.norm(x)\n",
    "    else:\n",
    "         energy = 0\n",
    "    return energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract snare**\n",
    "Find chorus of the song by searching for a frame with the highet energy (dirty hack but works fine)\n",
    "Extract percussive audio with HPSS\n",
    "Detect onsets (delta=0.08, wait=3 parameters are actually highly tuned)\n",
    "Only select onsets with energy higher than the median (for having a small selection for manuall labelling of kick and snare sounds)\n",
    "Concatenate onsets of the size of one frame together with silence at the end\n",
    "Save sample to .wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_snare(path, song_name):\n",
    "    x, sr = librosa.load(path, sr=SR)\n",
    "    main_struct_frame = int(sr*(60/(BPM/8)))\n",
    "    max_frame_energy = 0\n",
    "    found_i = 0\n",
    "    for i in range(0, int((len(x) / main_struct_frame))):\n",
    "        frame = i*main_struct_frame\n",
    "        \n",
    "        #hackthis\n",
    "        #frame_energy = librosa.feature.rmse(y=x[frame:frame+main_struct_frame])\n",
    "        #frame_energy = np.max(frame_energy[0])\n",
    "        \n",
    "        frame_energy = extract_features(x[frame:frame+main_struct_frame])\n",
    "        if (frame_energy > max_frame_energy):\n",
    "            found_i = i\n",
    "            max_frame_energy = frame_energy\n",
    "            print(found_i)\n",
    "        \n",
    "    #x = speed_adjust(x, sr)\n",
    "    \n",
    "    ###quick hack for second wave of files\n",
    "    #found_i = 0\n",
    "    \n",
    "    x = x[(found_i*main_struct_frame):((found_i+1)*main_struct_frame)]\n",
    "    print(len(x))\n",
    "\n",
    "    X = librosa.stft(x)\n",
    "    H, P = librosa.decompose.hpss(X, power=3.0, margin=(1,2))\n",
    "    p = librosa.istft(P)\n",
    "\n",
    "    onset_frames = librosa.onset.onset_detect(p, sr=sr, delta=0.08, wait=3) #0.04 #4\n",
    "    #onset_times = librosa.frames_to_time(onset_frames, sr=sr)\n",
    "    onset_samples = librosa.frames_to_samples(onset_frames)\n",
    "    \n",
    "    frame_sz = int(SR*FRAME_SIZE) #0.090\n",
    "    f_energy = np.array([extract_features(p[i:i+frame_sz]) for i in onset_samples])\n",
    "\n",
    "    median_energy = np.median(f_energy)\n",
    "    print(f_energy)\n",
    "    silence = np.zeros(int(PAD_DURATION*SR)) #silence\n",
    "    frame_sz = min(np.diff(onset_samples))   #every segment has uniform frame size\n",
    "    frame_sz_long = int(frame_sz*1.2)\n",
    "    for i, onset in enumerate(onset_samples):\n",
    "        if (f_energy[i] > median_energy):\n",
    "            sample = np.concatenate([p[onset:onset+frame_sz_long], silence]) # pad segment with silence\n",
    "            librosa.output.write_wav(POST_PERCUSSION+'/'+song_name+'_'+str(f_energy[i])+'_'+str(i)+\".wav\", sample, SR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract rythm**\n",
    "Depracated. Instead extract_snare is adjusted to work universally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"                        \n",
    "def extract_rythm(path, song_name):\n",
    "    print(path)\n",
    "    x, sr = librosa.load(path, sr=SR)\n",
    "    \n",
    "    X = librosa.stft(x)\n",
    "    H, P = librosa.decompose.hpss(X, power=3.0, margin=(1,2))\n",
    "    p = librosa.istft(P)\n",
    "        \n",
    "    #p = speed_adjust(x, sr)  #p\n",
    "    main_struct_frame = int(sr*(60/(BPM/8)))\n",
    "    max_frame_energy = 0\n",
    "    found_i = 0\n",
    "    for i in range(0, int((len(p) / main_struct_frame))):\n",
    "        frame = i*main_struct_frame\n",
    "        \n",
    "        frame_energy = extract_features(p[frame:frame+main_struct_frame])\n",
    "        if (frame_energy > max_frame_energy):\n",
    "            found_i = i\n",
    "            max_frame_energy = frame_energy\n",
    "            print(found_i)\n",
    "           \n",
    "    p = p[(found_i*main_struct_frame):((found_i+1)*main_struct_frame)]\n",
    "    \n",
    "    onset_frames = librosa.onset.onset_detect(p, sr=sr, backtrack=True, hop_length=512)\n",
    "    onset_times = librosa.frames_to_time(onset_frames, sr=sr)\n",
    "    clicks = librosa.clicks(times=onset_times, length=len(p))\n",
    "    librosa.output.write_wav(\"beat_detector_clicks.wav\", p+clicks, SR)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main**\n",
    "Run sound extraction for all sounds in dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        \n",
    "def main():\n",
    "    print(\"Main\")\n",
    "    main_dir = os.getcwd()+'/'+PRE_AUDIO\n",
    "    for subdir, dirs, files in os.walk(main_dir):\n",
    "        for i, file in enumerate(files):\n",
    "            if i > 0:\n",
    "                path = os.path.join(subdir, file)\n",
    "                print(path)\n",
    "                #extract_snare(path,file)\n",
    "                #extract_sound(path, file)\n",
    "    \n",
    "main()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
